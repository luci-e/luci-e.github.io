<!doctype html>
<html lang="it">

<head>
    <meta charset="utf-8">
    <title>ML notes</title>
    <meta name="author" content="Emiliano">
    <link rel="stylesheet" href="css/style.css?v=1.0">
    <script type="text/javascript" src="js/script.js"></script>
</head>

<body>
    <div id="center_column">
        <div id="main_title"> ML para dummies</div>
        <div class="info_box">
            <h1> Decision Trees </h1>
            <i>Maybe you are, and maybe you aren't. The White Wizard will know. - Treebeard a poorly trained decision tree can't classify Merry and Pippin as hobbits</i>
            <br>
            <div class="info_text">
                <p>The number of distinct truth table for n variables are 2^(2^n) the first 2 is for the output value, 2^n are the number of rows.</p>
                <p>An hypothesis for conjunctive functions can be represented with a vector of n features. The vector is filled with 0, 1, ? (don't care), and null. Since all hypothesis with at least a null are equivalent the |H| = 3^n + 1</p>
                <p>Given two hypotheses h1 and h2, h1 is more general than or equal to h2 (h1 >= h2) iff every instance that satisfies h2 also satisfies h1.</p>
                <p>Given two hypotheses h1 and h2, h1 is (strictly) more general than h2 (h1>h2) iff h1 >= h2 and it is not the case that h2 >= h1.</p>
                <p>To decide how to split the data when building a tree we use entropy. Given a dataset D with c categories entropy is defined as:
                </p><img src="./img/0.png" class="equation_img" /> Where p_i is the percentage of the data belonging to that class.
                <p>We pick the feature that gives use the highest information gain, which is defined as</p>
                <img src="./img/1.png" class="equation_img" />
                <p>Each branch of the tree defines a rule. Each rule has a support |D_v| / |D| and a confidence |D_v+| / |D_v|</p>
                <p>Building a tree is expensive and may lead to overfitting of the data, i.e. when the hypothesis we've found works worst on independent test data. So we must prune the tree.
                    <br>We can either pre-prune, that is, we stop growing the tree when we have no sufficient data left or post-prune, when we grow the full tree then remove sub-trees with insufficient evidence.
                    <br>We label the newly created leaf with a majority function evaluated on the subtree.</p>
            </div>
        </div>
        <div class="info_box">
            <h1>Performance Evaluation</h1>
            <i>I can see the confusion matrix - Neo </i>
            <br>
            <div class="info_text">
                <p>A confusion matrix ( or contigency table ) is a table of four elements:
                    <ul>
                        <li>TP: “true positive”, i.e., number (or %) of positive instances classified as positive by the system</li>
                        <li>FP: “false positive”, should be negative, the system classified as positive </li>
                        <li>TN: “true negative” negative instances classified as negative</li>
                        <li>FN: “false negative” positive instances classified as negative</li>
                    </ul>
                </p>
                <p>We also define the following measures:
                    <ul>
                        <li>Total = TP + FP + TN + FN</li>
                        <li>Accuracy = (TP + TN) / Total</li>
                        <li>Precision = TP / ( TP + FP ) </li>
                        <li>Recall = TP / ( TP + FN )</li>
                        <li>F-Measure = 2( P x R ) / ( P + R )</li>
                    </ul>
                </p>
                <p>The Receiver Operating Characteristic curve ( ROC curve hello biometrics ) is a plot of the true positive rate against the false positive rate as the discrimination threshold is varied. </p>
                <p>Given an hypotesis we must evaluate the error. For a sample of the data the sample error is:</p>
                <img src="./img/2.png" class="equation_img" /> Where the delta function is 1 if the two arguments are different, 0 otherwise.
                <p>The true error instead is: </p>
                <img src="./img/3.png" class="equation_img" /> Where D is a probability distribution according to which we pick the samples.
                <p>Call p the true error probability of h. We know that we made r errors over n instances. We can estimate p since our error function follows a bynomial distribution with mean value p. </p>
                <p>Stuff you need to know about the bynomial distribution: </p>
                <img src="./img/4.png" class="equation_img" />
                <p>Now forget all about it since for a large number of samples the bynomial distribution approximates a normal distribution. This is thanks to the Central Limit Theorem which states that the arithmetic mean of a sufficiently large number of experiments of independent random variables, each with a well-defined expected value and well-defined variance, will be approximately normally distributed. This is also known as when you don't know the underlying distribution go for a gaussian. </p>
                <img src="./img/7.png" class="equation_img" /> Or with Bessel's correction for small ns
                <img src="./img/8.png" class="equation_img" />
                <p>Also there's this thing called bias which I guess is important or something: </p>
                <img src="./img/9.png" class="equation_img" />
                <p>A confidence interval for an estimate Δ is an interval [LB,UB] that includes Δ with probability N% (with probability N% we have LB≤Δ≤UB) in our case we're interested in:</p>
                <img src="./img/10.png" class="equation_img" />
                <p>Since the estimated error and true error follow a gaussian with the same mean they will also have the same standard deviation. For a normal distribution we have these things called z-tables that gives us the integral of half the curve at a distance z from the mean. The z-score is simply z / sigma. Normally the z-tables are given for the standard deviation = 1</p>
                <p>Finally we can compute our confidence interval as </p>
                <img src="./img/11.png" class="equation_img" />
                <p>When we have 2 hypothesis it may be that one is better than the other. Clearly the first thing we can compute is the error difference</p>
                <img src="./img/12.png" class="equation_img" />
                <p>We must then test our supposition against the null hypothesis, that is the one that says what we're claiming isn't true. We have 3 cases depending on what we're testing.
                    <ul>
                        <li>Two tail test, if d != 0:
                            <ul>
                                <li>H0: data do not support that there is a difference between h1 and h2, hence errorD(h1)-errorD (h2) = 0 </li>
                                <li>H1: there is indeed a (statistically significant) difference between h1 and h2 </li>
                            </ul>
                        </li>
                        <li>
                            One-tail right-test (we find that d > 0)
                            <ul>
                                <li>H0: data do not support that h2>h1 </li>
                                <li>H1: h2>h1 (error of h1 is significantly lower)</li>
                            </ul>
                        </li>
                        <li>One-tail left-test (we find that d
                            < 0) <ul>
                                <li>H0: data do not support that h2
                                    < h1 </li>
                                        <li>H1: h1>h2 (error of h1 is significantly higher) </li>
                    </ul>
                    </li>
                    </ul>
                </p>
                <p>We also introduce the concept of p-value, that is the probability of of observing a given value. </p>
                <p>Since our error difference is a difference of normally distributed random variables it must be a normally distributed random variable itself. With standard deviation equal to the sum of the standard deviations </p>
                <p>In the two tail test we accept the null hypothesis if the likelyhood that the mean error difference is 0 lies within 2 standard deviation </p>
                <img src="./img/13.png" class="equation_img" /> Since we have z we can now compute whether we lie in the non-critical region (N ≤ 95%), where we accept the null hypothesis.
                <p>In the one tail test, we compute the z-value and 1 - the probability of lying on the right (left test) or on the left (right test) must be less than the p-value</p>
                <p>Something something something k-fold cross validation something something something completely skipped</p>
            </div>
        </div>
        <div class="info_box">
            <h1>Neural Networks</h1>
            <i>After discovering he was just a pile of linear algebra the NN began his gradient descent towards alcoholism - from The tales of the Perceptrons</i>
            <br>
            <div class="info_text">
                <p>The simplest NN is a Perceptron that is a single layer network. The Perceptron has as state the weights vector and the threshold function. It takes in input a vector of values and outputs 1 or 0. So what it does is linearly separate an hyperspace.</p>
                <img src="./img/14.png" class="equation_img" />
                <p>How to train your perceptron: give him a hint of what's "right" by providing him with a training set, that is a pair of
                    < input, expected output> and adjusting the weights at each iteration, also adjust the threshold at each iteration. You can initialize the threshold and weights at random, since by the Perceptron Convergence theorem IF the data is linearly separable then there exists a valid set of weight vector and threshold values pairs and the algorithm will eventually converge to one of them. On the other hand if it's not the algorithm will just cycle on a set of values</p>
                <img src="./img/15.png" class="equation_img" />
                Here the t_j are the training set outputs. In the slides there is an i on the weights because in multilayerd networks each neuron can be connected to multiple other neurons and the weights are on the edges of the graph but in Perceptrons we have the weights on the nodes so the i makes no feckin sense but nooo let's keep the notation all wibbly wobbly mixed right Mrs. Velardi? Ugh, I can't even. Anyway that's all for Perceptrons, NN in disguise.
                <p>Multi-Layer networks are NN that can represent arbitrary functions. There's some math(sss) ahead so buckle up, get a cuppa, go review some matrix notation cause those sums are a fuckin eyesore and go look up the Chain rule for differentiation before starting otherwise the last part won't make sense. Or don't do any of that, I'm just a website not your father.</p>
            </div>
        </div>
        <div class="info_box">
            <h1></h1>
            <i></i>
            <br>
            <div class="info_text"></div>
        </div>
    </div>
</body>

</html>